{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "4977d7d6-5e10-4415-a3fe-53c578b055f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def linear(x):\n",
    "    return x\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0,x)\n",
    "\n",
    "def softmax(x):\n",
    "    new_x = np.zeros_like(x)\n",
    "    for idx in range(x.shape[0]):\n",
    "        tmp = x[idx,:]\n",
    "        m = np.max(tmp)\n",
    "        tmp -= m\n",
    "        new_x[idx] = np.exp(tmp)/np.sum(np.exp(tmp))\n",
    "    return new_x\n",
    "\n",
    "def tanh(x):\n",
    "    return (np.exp(x)-np.exp(-x))/(np.exp(x)+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "fa5f00c1-e25f-48b5-bf7c-d2649882e120",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_squared_error(t,y):\n",
    "    return np.mean(np.square(t-y))\n",
    "\n",
    "def binary_crossentropy(t,y):\n",
    "    return -np.mean(t*np.log(y) + (1-t)*np.log(1-y))\n",
    "\n",
    "def categorical_crossentropy(t,y):\n",
    "    eps = 1e-7\n",
    "    return -np.mean(t*np.log(y+eps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "4d71efe5-02fe-480d-8fc1-5d3305f9376e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# def linear(x):\n",
    "#     return x\n",
    "\n",
    "# def sigmoid(x):\n",
    "#     return 1/(np.exp(-x)+1)\n",
    "\n",
    "# def relu(x):\n",
    "#     return np.maximum(x, 0)\n",
    "\n",
    "# def softmax(x):\n",
    "#         new_x = np.zeros_like(x)\n",
    "#         for idx in range(x.shape[0]):\n",
    "#             tmp = x[idx,:]\n",
    "#             m = np.max(tmp)\n",
    "#             tmp -= m\n",
    "#             new_x[idx] = np.exp(tmp)/np.sum(np.exp(tmp))\n",
    "#         return new_x\n",
    "    \n",
    "# def tanh(x):\n",
    "#     return (np.exp(x) - np.exp(-x))/(np.exp(x) + np.exp(-x))\n",
    "\n",
    "# def mean_squared_error(t,y):\n",
    "#     return np.mean(np.square(t-y))\n",
    "\n",
    "# def binary_crossentropy(t,y):\n",
    "#     return -np.mean(t*np.log(y) + (1-t)*np.log(1-y))\n",
    "\n",
    "# def categorical_crossentropy(t,y):\n",
    "#     eps = 1e-7\n",
    "#     return -np.mean(t*np.log(y+eps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "139c7f73-3bc7-46b3-a185-d81b6952f7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU:\n",
    "    def __init__(self):\n",
    "        self.out = None\n",
    "    \n",
    "    def forward(self,x):\n",
    "        out = np.maximum(0,x)\n",
    "        self.out = np.where(out > 0,1, 0)\n",
    "        return out \n",
    "    \n",
    "    def backward(self,out):\n",
    "        dout = self.out*out\n",
    "        return dout\n",
    "\n",
    "\n",
    "class Sigmoid:\n",
    "    def __init__(self):\n",
    "        self.out = None\n",
    "    \n",
    "    def forward(self,x):\n",
    "        return sigmoid(x)\n",
    "    \n",
    "    def backward(self,out):\n",
    "        dout = sigmoid(out)*(1-sigmoid(out))\n",
    "        return dout\n",
    "\n",
    "class Affine:\n",
    "    def __init__(self,w,b):\n",
    "        self.x = None\n",
    "        self.w = w\n",
    "        self.b = b\n",
    "   \n",
    "    def forward(self,x):\n",
    "        self.x = x  \n",
    "        self.out = np.dot(self.x,self.w) + self.b\n",
    "        return self.out\n",
    "   \n",
    "    def backward(self,out):\n",
    "        dout = np.dot(out,self.w.T) # 100,10\n",
    "        dW = np.dot(self.x.T,out)\n",
    "        db = np.sum(out,axis=0)\n",
    "        return dout\n",
    "\n",
    "class Tanh:\n",
    "    def __init__(self):\n",
    "        self.out = None\n",
    "    \n",
    "    def forward(self,x):\n",
    "        self.out = tanh(x)\n",
    "        return self.out\n",
    "    \n",
    "    def backward(self,out):\n",
    "        dout = 1-tanh(out)**2\n",
    "        return dout\n",
    "\n",
    "class SoftmaxWithLogit:\n",
    "    def __init__(self):\n",
    "        self.out = None\n",
    "        self.y = None\n",
    "        self.y_pred = None\n",
    "    \n",
    "    def forward(self,x):\n",
    "        self.y_pred = softmax(x)\n",
    "        return self.y_pred\n",
    "    \n",
    "    def backward(self,out=1):\n",
    "        out = 1\n",
    "        self.dout = out*(self.y - self.y_pred)\n",
    "        return self.dout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "3fd140f7-8b68-45e5-8b5c-77bc615b9d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net:\n",
    "    def __init__(self,input_shape):\n",
    "        self.x = None\n",
    "        self.y = None\n",
    "        self.input_shape=input_shape\n",
    "        self.layers = []\n",
    "        self.activation_dic = {\n",
    "            'relu':ReLU,\n",
    "            'sigmoid':Sigmoid,\n",
    "            'tanh':Tanh,\n",
    "            'softmax':SoftmaxWithLogit,\n",
    "        }\n",
    "        \n",
    "    def add(self,output_shape,activation):\n",
    "        if len(self.layers) == 0:\n",
    "            w = np.random.randn(self.input_shape,output_shape)\n",
    "            b = np.zeros(output_shape)\n",
    "            activation = activation\n",
    "            self.layers.append([w,b,activation])\n",
    "        else:\n",
    "            input_shape = self.layers[-1][0].shape[1]\n",
    "            w = np.random.randn(input_shape,output_shape)\n",
    "            b = np.zeros(output_shape)\n",
    "            activation = activation\n",
    "            self.layers.append([w,b,activation])\n",
    "    \n",
    "    def _build(self):\n",
    "        self.W = {}\n",
    "        for i,layer in enumerate(self.layers):\n",
    "            w = layer[0]\n",
    "            b = layer[1]\n",
    "            activation = layer[2]\n",
    "            self.W['Affine_'+str(i+1)] = Affine(w,b)\n",
    "            self.W['Activation_'+str(i+1)] = self.activation_dic[activation]\n",
    "        return f'Building Success !!'\n",
    "    \n",
    "    def predict(self,x):\n",
    "        if self.grad is None:\n",
    "            self._build()\n",
    "        self.y_pred = x\n",
    "        for k,v in self.W.items():\n",
    "            if 'Affine' in k:\n",
    "                self.y_pred = v.forward(self.y_pred)\n",
    "            else:\n",
    "                self.y_pred = v.forward(self.y_pred)\n",
    "        return self.y_pred\n",
    "\n",
    "    def gradient(self,x,y):\n",
    "        self.y_pred = self.predict(x)\n",
    "        self.y = y\n",
    "        self.grad = {}\n",
    "        out = 1\n",
    "        last_layer = list(self.W.keys())[-1] \n",
    "        out = self.W.get(last_layer).backward(self.y,out)\n",
    "        for key in list(self.W.keys())[::-1]:\n",
    "            out = self.W.get(key).backward(out)\n",
    "        cnt = 1\n",
    "        for key in self.W.keys():\n",
    "            if 'Affine' in key:\n",
    "                self.grad['W'+str(cnt)] = self.W.get(key).dW\n",
    "                self.grad['b'+str(cnt)] = self.W.get(key).db\n",
    "                cnt += 1\n",
    "        return self.grad\n",
    "        \n",
    "        \n",
    "    def loss(self,x,y):\n",
    "        y_pred = self.predict(x)\n",
    "        loss_ = categorical_crossentropy(y,y_pred)\n",
    "        return loss_\n",
    "    \n",
    "    def descent_gradient(self,x,y):\n",
    "        loss_func = lambda W: self.loss(x,y)\n",
    "        for idx ,layer in enumerate(self.layers):\n",
    "            w = layer[0]\n",
    "            b = layer[1]\n",
    "            self.layers[idx][0] -= 0.001*grad(loss_func,w,b)[0]\n",
    "            self.layers[idx][1] -= 0.001*grad(loss_func,w,b)[1]\n",
    "        \n",
    "    \n",
    "    def summary(self):\n",
    "        total_params = 0\n",
    "        print('===========================================================')\n",
    "        print('------------------------Output Shape-------------params----')\n",
    "        for layer in self.layers:\n",
    "            print('------------------------ (None,',layer[0].shape[1],')------------',np.prod(layer[0].shape) + len(layer[1]),'----------')\n",
    "            total_params += np.prod(layer[0].shape) + len(layer[1])\n",
    "        print('===========================================================')\n",
    "        print('Trainable params ------',total_params)\n",
    "        \n",
    "        \n",
    "    def fit(self, x,y, epochs, lr=1e-3):\n",
    "        self.grad = self.gradient(x,y)\n",
    "        for epoch in range(epochs):\n",
    "            for idx in range(len(self.layers)):\n",
    "                self.W.get('Affine_'+str(idx+1)).w -= lr*self.grad('W'+str(idx+1))\n",
    "                self.W.get('Affine_'+str(idx+1)).b -= lr*self.grad('b'+str(idx+1))\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "3ad58de2-8dee-461d-ad61-ea5caec4166c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net(input_shape=784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "f5f68c51-84ee-457c-83b1-428569512220",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(256,activation='relu')\n",
    "model.add(256,activation='relu')\n",
    "model.add(256,activation='relu')\n",
    "model.add(128,activation='relu')\n",
    "model.add(10,activation='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163b3a10-8a02-4d11-b06b-1f4317851b2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "9e8d5958-9f9b-43d3-a7c0-a0e6fe8d03f4",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "forward() missing 1 required positional argument: 'x'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[166], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m784\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[163], line 48\u001b[0m, in \u001b[0;36mNet.gradient\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgradient\u001b[39m(\u001b[38;5;28mself\u001b[39m,x,y):\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my \u001b[38;5;241m=\u001b[39m y\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;241m=\u001b[39m {}\n",
      "Cell \u001b[0;32mIn[163], line 44\u001b[0m, in \u001b[0;36mNet.predict\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_pred \u001b[38;5;241m=\u001b[39m v\u001b[38;5;241m.\u001b[39mforward(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_pred)\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 44\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_pred \u001b[38;5;241m=\u001b[39m \u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_pred\n",
      "\u001b[0;31mTypeError\u001b[0m: forward() missing 1 required positional argument: 'x'"
     ]
    }
   ],
   "source": [
    "model.gradient(np.random.randn(100,784),np.random.randn(100,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "042ae48c-cf6a-4db7-a9a6-492fcacf152f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Net' object has no attribute 'backward'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[167], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m(np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m30\u001b[39m),np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m30\u001b[39m))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Net' object has no attribute 'backward'"
     ]
    }
   ],
   "source": [
    "model.backward(np.random.randn(10,30),np.random.randn(10,30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2984578e-cfb8-4989-8903-8942360f0620",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Affine' object has no attribute 'dW'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[133], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mW\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAffine_3\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdW\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Affine' object has no attribute 'dW'"
     ]
    }
   ],
   "source": [
    "model.W.get('Affine_3').dW.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66044dfe-1bca-4faa-ac87-66790fe0180a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 5)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.random.randn(10,30)\n",
    "model.forward(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5589b33-cce9-490f-bebf-6eaf05636251",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Affine_1': <__main__.Affine at 0x7f6072ff5a90>,\n",
       " 'Activation_1': __main__.ReLU,\n",
       " 'Affine_2': <__main__.Affine at 0x7f607348a610>,\n",
       " 'Activation_2': __main__.ReLU,\n",
       " 'Affine_3': <__main__.Affine at 0x7f607348ac70>,\n",
       " 'Activation_3': __main__.SoftmaxWithLogit}"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "9a039a2b-7d97-4e10-92c5-a2ddd64fbbf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Affine_1', 'Activation_1', 'Affine_2', 'Activation_2', 'Affine_3', 'Activation_3'])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.W.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "1ea88ae0-9fb2-4177-8e24-443a76211466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'relu': __main__.ReLU,\n",
       " 'sigmoid': __main__.Sigmoid,\n",
       " 'tanh': __main__.Tanh,\n",
       " 'softmax': __main__.SoftmaxWithLogit}"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.activation_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "122b7270-3485-4920-b939-9de77a24c8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.randn(10,30)\n",
    "for layer in model.layers[:-1]:\n",
    "    w = layer[0]\n",
    "    b = layer[1]\n",
    "    activation = model.activation_dic.get(layer[2])\n",
    "    x = activation().forward(np.dot(x,w) + b)\n",
    "# w, b, activation = model.layers[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "6cf5a4a9-5091-47df-980e-18166560ba67",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.randn(10,30)\n",
    "for key in model.W.keys():\n",
    "    if 'W' in key :\n",
    "        x = np.dot(x,model.W[key])\n",
    "    if 'b' in key:\n",
    "        x = x + model.W[key]\n",
    "    if 'Acti' in key:\n",
    "        x = model.W[key]().forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "599cee37-a1db-4c0b-ba76-ad8ab720b1b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 30)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415e0569-7ec2-4a61-9b9f-cd6e14c66085",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bteam",
   "language": "python",
   "name": "bteam"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
